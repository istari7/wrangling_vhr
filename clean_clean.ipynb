{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression for validating an Email \n",
    "#Logic Copy Pasta from here for the email regex expression. It was the best working one that worked across 90k plus emails\n",
    "#https://emailregex.com/\n",
    "regex = r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "\n",
    "# We will be checking the row length after each operation for better clarity regarding the number of ops performed\n",
    "\n",
    "## After importing the data file the Order of Operations are\n",
    "\n",
    "\n",
    "1. Dropping all Empty Fields\n",
    "2. Dropping all Fields with Multiple Empty Characters\n",
    "3. Changing all to lowercase\n",
    "4. Splitting and extracting multiple emails from the fields\n",
    "5. Ensuring emails are unique in each field\n",
    "6. Creating new rows for multi emails\n",
    "7. Dropping all duplicates\n",
    "8. Email Validation. If valid- > leave as it is. If not. Drop the row\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row length --> 22797\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_excel(\"clean.xlsx\")\n",
    "df = pd.DataFrame(raw_data)\n",
    "row_length, _ = df.shape\n",
    "print(\"Row length -->\",row_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping all the Empty Fields below and also the ones with multiple empty characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row length --> 22767\n"
     ]
    }
   ],
   "source": [
    "#Checking for empty and throwing away value\n",
    "#Here NaN represents empty or you can say null\n",
    "df.dropna(subset=['Email'],inplace=True)\n",
    "#ALso check for empty strings after this. Just in case\n",
    "#Below is code for regex check for longer empty string like '     '\n",
    "df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df.dropna(subset=[\"Email\"],inplace=True)\n",
    "row_length, _ = df.shape\n",
    "print(\"Row length -->\",row_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change all to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Email'] = df['Email'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few helper functions that come in handy later on for data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a few helper functions for repeated use\n",
    "#Trims and splits based on spaces\n",
    "def despacer_decomma(x):\n",
    "    x = x.strip()\n",
    "    x = x.split(\",\")\n",
    "    x = \" \".join(x)\n",
    "    x = x.split(\" \")\n",
    "    return x\n",
    "'''\n",
    "For removing false positives and weird chars in btwn valid emails, if the user uses some weird kind of characters for separating his email like ;; or -x- or ---- \n",
    "The smallest email can be of the size 6 characters. Using that heuristic we use the below logic to clear all the false positives\n",
    "'''\n",
    "def remover(x):\n",
    "    if len(x) < 6:\n",
    "        return None\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def size_based_email_cleaner(l):\n",
    "    l = list(map(remover,l))\n",
    "    l = list(filter(None,l))\n",
    "    return l\n",
    "\n",
    "# Define a function for \n",
    "# for validating an Email \n",
    "def check(email):  \n",
    "    # pass the regular expression \n",
    "    # and the string in search() method \n",
    "    if(re.search(regex,email)):  \n",
    "        return True\n",
    "          \n",
    "    else:  \n",
    "        return False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email Splitting and Cleaning with the same field. Also remove case insensitive duplicates here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    val = df.at[i, \"Email\"]\n",
    "    val1 = despacer_decomma(val)\n",
    "    val2 = list(set(size_based_email_cleaner(val1)))\n",
    "    df.at[i, \"Email\"] = val2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking those multiple emails and creating multiple entries from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row length --> 24225\n"
     ]
    }
   ],
   "source": [
    "for i in df.index:\n",
    "    val = df.at[i, \"Email\"]\n",
    "    if len(val)>1:\n",
    "        core = val[0]\n",
    "        if type(val) is type(\" \"):\n",
    "            continue\n",
    "        while len(val) > 1:\n",
    "            temp_val = val.pop()\n",
    "            new_df = df.loc[i, :]\n",
    "            new_df.at[\"Email\"] = str(temp_val)\n",
    "            df = df.append(new_df,ignore_index=True)\n",
    "    #Uncomment below row to see each email that is appended and new row that is created\n",
    "   #         print(\"New Row Duplicated with Following Email :-\",new_df[\"Email\"])\n",
    "        df.at[i,\"Email\"] = core\n",
    "#Converting the list datatype in the col to a string one\n",
    "for i in df.index:\n",
    "    df.at[i, \"Email\"] = \"\".join(df.at[i, \"Email\"])\n",
    "row_length, _ = df.shape\n",
    "print(\"Row length -->\",row_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping all the duplicate values from the entire sheets with Email as Primary Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row length --> 15610\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset = [\"Email\"])\n",
    "row_length, _ = df.shape\n",
    "print(\"Row length -->\",row_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping all the cells where the email is invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This email is invalid 646-715-4014|yomi.obafemi@gmail.com\n",
      "This email is invalid nicolecpelham@yahoo.comlovsom@sbcglobal.net\n",
      "This email is invalid thervada@pol.netthervada58@yahoo.com\n",
      "This email is invalid rscherr@gshleb.orgrobertascherr@yahoo.com\n",
      "This email is invalid glorskymd@aol.comsteven.glorsky@ttuhsc.edu\n",
      "This email is invalid nlyubyn@gmail.comnlyubyn@med.umich.edu\n",
      "This email is invalid olgawiley@kk\n",
      "This email is invalid krvssiewoods@gmailcom\n",
      "This email is invalid 516-343-5948*deborahastein@gmail.com\n",
      "This email is invalid abachiller10@gmailcom\n",
      "This email is invalid ?laurenstrick@yahoo.com\n",
      "This email is invalid 413-301-6544/jjzipagan@gmail.com\n",
      "This email is invalid wcmust2@email\n",
      "This email is invalid 381-7647/cmmmd2870@yahoo.com\n",
      "This email is invalid |felipeorellana.do@gmail.com\n",
      "Cleaning Completed\n",
      "Row length --> 15595\n"
     ]
    }
   ],
   "source": [
    "for i in df.index:\n",
    "    val = df.at[i, \"Email\"]\n",
    "    if check(val):\n",
    "        continue\n",
    "    else:\n",
    "        print(\"This email is invalid\",val)\n",
    "        df.at[i, \"Email\"] = np.nan\n",
    "print(\"Cleaning Completed\")\n",
    "df.dropna(subset=['Email'],inplace=True)\n",
    "row_length, _ = df.shape\n",
    "print(\"Row length -->\",row_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the file to the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"new_clean.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disclaimer :- For running this out of the box :- delete all column headers before calling the file, and paste back after wrangling. There is some weird bug that corrupts the dataframe in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
